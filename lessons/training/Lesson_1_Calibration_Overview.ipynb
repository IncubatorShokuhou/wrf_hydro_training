{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Calibration Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamically Dimensioned Search:\n",
    "We need some general content on the DDS ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programs & Workflow:\n",
    "Calibration workflow is run through a series of six individual python scripts, typically run from the command line (terminal). The python scripts must be run in order, and only once the previous script has completed. Brief descriptions of each script are provided below and more detailed explanation would be provided in the upcoming lessons. \n",
    "\n",
    "![WorkFlow_Image_Placeholder](imagename.png \"Image Placeholder for now\")\n",
    "\n",
    "*initDB.py:* \n",
    "\n",
    "This program is used one time to initialize the calibration database and associated tables used during the experiment. Completing this step will create an empty database with all the relevant tbales that will be filled with information provided during the calibration procedure. More information will be provided in Lesson 2. \n",
    "\n",
    "\n",
    "*inputDomainMeta.py:* \n",
    "\n",
    "This program reads in a CSV file you will need to fill out that describes modeling domains to be used for calibration. This information is entered into the database for later workflow use. More description on the CSV will occur during the setup section (Lesson 2).\n",
    "\n",
    "*jobInit.py:* \n",
    "\n",
    "This program is run to establish a calibration ‘experiment’. The program reads a config file \n",
    "(explained in depth below) and sets up the necessary run directories, paths to necessary files, and inputs associated metadata into the database. Upon successful completion, the program will return a unique job ID value which you will use in subsequent programs to run the calibration.\n",
    "\n",
    "*spinOrchestrator.py*\n",
    "\n",
    " This is the first program that is run to initialize the calibration experiment. The only mandatory argument to this program is the unique job ID for the calibration experiment. The main purpose of this program is to run the NWM/WRF-Hydro spinup for all domains being calibrated. This program needs to successfully complete before moving onto the next step.\n",
    "\n",
    "\n",
    "*calibOrchestrator.py:* \n",
    "\n",
    "This is the second program that is run in the calibration workflow. As with spinup.py, the only mandatory argument is the job ID value. This program runs the main workflow to adjust parameter values, execute interim model simulations, evaluate model output against observations, and further adjust parameter values. This program must be completed successfully before moving onto the next step.\n",
    "\n",
    "*runValidOrchestrator.py:*\n",
    "\n",
    "This is the third and final main program in the calibration workflow. The only mandatory argument is the unique job ID value associated with the calibration experiment. This program manages running the model with the final calibrated parameters over a specified evaluation period for the evaluation of the parameters.\n",
    "\n",
    "*getJobID.py:*\n",
    "\n",
    "This program will return the job ID to you in the cases where you have forgotten your unique job ID for the calibration experiment. The calibration config file is used as input into this program.\n",
    "spinup.py: This is the first program that is run to initialize the calibration experiment. The only mandatory argument to this program is the unique job ID for the calibration experiment. The main purpose of this program is to run the NWM/WRF-Hydro spinup for all domains being calibrated. This program needs to successfully complete before moving onto the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Calibration Step 1: Configure Setup File: \"setup.parm\"\n",
    "The primary file you will be editing in preparation for setting up a calibration workflow job is the ‘setup.parm’ file. It is best to think of this file as a master configuration file to guide the workflow. This file contains multiple options that define how the workflow will submit jobs for models/analysis, which basins to calibrate from the database, methods for reporting errors to the user, model physics options, and paths to general parameter files and executables.\n",
    "The ‘setup.parm’ file is divided up into sections: logistics, gageInfo, lsmPhysics, forcing, modelTime, hydroIO, and hydroPhysics. The first section of the setup.parm file is ‘logistics’, which guides the workflow. Let s take a look at the this file and its content: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calib_params.tbl\n",
      "domainMetaTemplate.csv\n",
      "gage_list_template.csv\n",
      "sens_params.tbl\n",
      "setup.parm\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/docker/PyWrfHydroCalib/setup_files/\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note file: 'setup.parm' \n",
    "(Users can open a terminal session in jupyter notebook and copy/paste the following command to view this file-->\n",
    "*vi setup.parm*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the setup file content. \n",
    "As mentioned above the setup file had different sections which each target a specific part of the model calibration. Below we are providing a short description of each section and its arguments. \n",
    "\n",
    "## logistics section\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "| **outDir** | Req. |Where do you want your calibration experiment to be constructed? |\n",
    "|**expName** | Req. |What is the name of your experiment. This can be anything you want. |\n",
    "|**acctKey** | Opt. |If you are running on a que system that requires credentials to submit a job, specify your account key here. |\n",
    "|**optQueName** | Opt. |If you need to direct model simulations/jobs to a specific que, you can specify that here. |\n",
    "|**nCoresModel** | Req. |How many CPUs are you running your model simulations over? |\n",
    "|**nNodesModel** | Req.| If you are running across multiple nodes on a que system, specify here.| \n",
    "|**nCoresPerNode** | Req. |If you are running on a que system, specify how many CPU cores you have available per node. |\n",
    "|**runSens** | Req.| Are we running sensitivity analysis? 0 - No, 1 - Yes |\n",
    "|**sensParmTbl** | Req.| Path to the table of parameter values to use in sensitivity analysis. Same format as the calibration parameter table. |\n",
    "|**runCalib** | Req. |Are we running calibration? 0 - No, 1 - Yes |\n",
    "|**calibParmTbl** | Req.| Path to the table of parameter values to use in calibration. |\n",
    "|**dailyStats** | Req. | Flag to direct worfklow to calculate error statistics on a daily scale, instead of hourly by default. Specify 1 to activate. |\n",
    "|**dbBackup** |?| >> *AREZOO* Flag to turn on/off database backup. If on, the databse will be locked and backed up once an hour during execution to the job directory output file.|\n",
    "|**coldStart** | Req. |Flag to direct calibration workflow to cold start your model simulation for each iteration during calibration. Specify 1 to activate. |\n",
    "|**optSpinFlag** | Req. | Flag to direct the workflow to use an alternative spinup file already in place in the input directory for the basins being calibrated. This allows the user to bypass the spinup step. Specify 1 to activate. |\n",
    "|**stripCalibOutputs** | Req. |If you desire to ommit outputs during an intial window for each model iteration, you can specify 1 here to activate this feature. This was designed to minimize I/O model burdens. |\n",
    "|**stripCalibHours** | Req. |Specify an initial window in hours to strip outputs. This is only used if stripCalibOutputs has been activated. |\n",
    "|**jobRunType** | Req. |This will specify how the model simulations and calibration code being executed. |\n",
    "|**mpiCmd** | Req. |What is the MPI command being used to execute the model simulations. This is required, as the MPI command is also used in job scheduler scripts. |\n",
    "|**cpuPinCmd** |Opt. |If you are running on a job scheduler, how do you want to pin specific model simulations on a compute node? This put in to allow multiple basins on one node. |\n",
    "|**numIter** | Req. |How many model iterations would you like to run your calibration experiment over? |\n",
    "|**calibMethod** | Req.| Right now only DDS is allowed. Future upgrades will incorporate additional calibration methods.|\n",
    "|**enableStreamflowCalib**| Req.| *AREZOO* specify if streamflow will be calibrated, 0- not calibrating, 1 - calibrating | \n",
    "|**enableSnowCalib**| Req. | *AREZOO* specify if snow input data will be used in calibration, 0- not calibrating, 1 -calibrating.\n",
    "|**streamflowObjectiveFunction** | Req.|Select what error metric for streamflow to minimize during the calibraion experiment. |\n",
    "|**snowObjectiveFunction** | Req.|Select what error metric for snow to minimize during the calibraion experiment. |\n",
    "|**soilMoistureObjectiveFunction** |Req.|Select what error metric for soil moisture to minimize during the calibraion experiment. |\n",
    "|**streamflowWeight**| Req. | *AREZOO* Apply weight to streamflow calibration|\n",
    "|**snowWeight**| |Req.|*AREZOO* Apply weight to the snow measurement calibration|\n",
    "|**soilMoistureWeight** |Req.|*AREZOO* Apply weight to soil moisture calibration|\n",
    "|**basinType**| Req. |*AREZOO* 0 - snowy, 1- slow, 2-flashy|\n",
    "|**weight1Event**| Req. | *AREZOO* weights for peak bias and volume bias to get combined|\n",
    "|**weight2Event**|Req.  | *AREZOO* weights for peak bias and volume bias to get combined|\n",
    "|**ddsR** | Req.| This is a DDS-specific parameter that tunes how random values are generated for each iteration. |\n",
    "|**enableMask**|Req.| *AREZOO* specify 1 to use mask covering part of basin, or 0 if not|\n",
    "|**enableMultiSites**|Req.| *AREZOO* Specify to calibrate to 1 or more streamgages|\n",
    "|**email** | Req. |Where do you want status and error messages to be directed to?|\n",
    "|**wrfExe** | Req.| Path to the WRF-Hydro executable to be used in the workflow. ]\n",
    "|**genParmTbl** | Req. |Path to the GENPARM.TBL file used by the model. |\n",
    "|**mpParmTbl** | Req. |Path to the MPARM.TBL file used by the model. |\n",
    "|**urbParmTbl** | Req. |Path to the URBPARM.TBL file used by the model. |\n",
    "|**vegParmTbl** | Req. |Path to the VEGPARM.TBL file used by the model. |\n",
    "|**soilParmTbl** | Req. |Path to the SOILPARM.TBL file used by the model. |\n",
    "|**bSpinDate** | Opt. |Beginning date for the spinup. |\n",
    "|**eSpinDate** | Opt. |Ending date for the spinup. |\n",
    "|**bCalibDate** | Req. |Beginning date for each calibration iteration. |\n",
    "|**eCalibDate** | Req. |Ending date for each calibration iteration. |\n",
    "|**bCalibEvalDate** | Req.| The date within each calibration iteration to begin analysis. |\n",
    "|**bValidDate** | Opt. |Beginning date for the validation simulation. |\n",
    "|**eValidDate** | Opt. |Ending date for the validation simulation. |\n",
    "|**bValidEvalDate** | Opt. |The date within the validation simulation to begin analysis. |\n",
    "\n",
    "### Sensitivity\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "|**sensParmSample** | Opt. |Sensitivity parameter sample size|\n",
    "|**sensBatchNum** | Opt. | How many sensitivity simulations to run at once. |\n",
    "|**bSensDate** | Opt. |Beginning date for the sensitivity model simulation. |\n",
    "|**eSensDate** | Opt. |Ending date for the sensitivity model simulation. |\n",
    "|**bSensEvalDate** | Opt. |The date within the sensitivity simulation to begin analysis. |\n",
    "\n",
    "### gageInfo\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "|**gageListSQL** | Req. |SQL command to extract basins for calibration out of the database file. |\n",
    "|**gageListFile** | Opt. |Alternative list of basins to calibrate instead of using an SQL command. |\n",
    "\n",
    "### lsmPhysics\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "|**SplitOutputCount**| Req.| Output Options: 1 - output 1 file per output time step, 0 - append all the timesteps to one file called LDASOUT_DOMAIN1.nc |\n",
    "|**dynVegOption** | Req. |DYNAMIC_VEG_OPTION for NoahMP. |\n",
    "|**canStomResOption** | Req. |CANOPY_STOMATAL_RESISTANCE_OPTION for NoahMP. |\n",
    "|**btrOption** | Req. BTR_OPTION for NoahMP. |\n",
    "|**runoffOption** | Req.| RUNOFF_OPTION for NoahMP. |\n",
    "|**sfcDragOption** | Req. |SURFACE_DRAG_OPTINO for NoahMP. |\n",
    "|**frzSoilOption** | Req. |FROZEN_SOIL_OPTION for NoahMP. |\n",
    "|**supCoolOption** | Req. |SUPERCOOLED_WATER_OPTION for NoahMP. |\n",
    "|**radTransferOption** | Req. |RADIATIVE_TRANSFER_OPTION for NoahMP. |\n",
    "|**snAlbOption** | Req.| SNOW_ALBEDO_OPTION for NoahMP. |\n",
    "|**pcpPartOption** | Req. |PCP_PARTITION_OPTION. |\n",
    "|**tbotOption** | Req. |TBOT_OPTINO for NoahMP. |\n",
    "|**tempTimeScOption** | Req.| TEMP_TIME_SCHEME_OPTION for NoahMP. |\n",
    "|**sfcResOption** | Req. |SURFACE_RESISTANCE_OPTION for NoahMP. |\n",
    "|**glacierOption** | Req. |GLACIER_OPTION for NoahMP. |\n",
    "|**soilThick** | Req. |Soil thicknesses for specified soil layers in NoahMP. |\n",
    "|**zLvl** | Req.| Level of wind speeds in NoahMP. |\n",
    "\n",
    "### forcing\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "|**forceType** | Req. |Specified forcing type. |\n",
    "\n",
    "### modelTime\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "|**forceDt** | Req. |Input forcing timestep in seconds. |\n",
    "|**lsmDt** | Req. |NoahMP timestep in seconds. |\n",
    "|**lsmOutDt** | Req. |NoahMp output timestep in seconds. |\n",
    "|**lsmRstFreq** | Req. |NoahMp restart frequency in seconds. |\n",
    "|**hydroRstFreq** | Req. |WRF-Hydro restart frequency in seconds. |\n",
    "|**hydroOutDt**  |Req. |WRF-Hydro output frequency in seconds. |\n",
    "\n",
    "### hydroIO\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "|**rstType** | Req. |Flag for overwritting accumulation vars in restart file. |\n",
    "|**SplitOoutputCount**| Req.| 1- output one CHANOB file per timestep, 0 - output one file containing all timesteps: CHANOBS_DOMAIN1.nc|\n",
    "|**ioConfigOutputs** | Req. |Output flag for varible grouping in WRF-Hydro. |\n",
    "|**ioFormOutputs** | Req. |Flag to for specifying output format. |\n",
    "|**chrtoutDomain** | Req. |Flag to turn on CHRTOUT_DOMAIN files. |\n",
    "|**chanObsDomain** | Req. |*AREZOO* Flag to turn on CHANOBS_DOMAIN files. |\n",
    "|**chrtoutGrid** | Req. |Flag to turn on CHRTOUT_GRID files. |\n",
    "|**lsmDomain** | Req. |Flag to turn on LSMOUT_DOMAIN files. |\n",
    "|**rtoutDOmain** | Req.| Flag to turn on RTOUT_DOMAIN files. |\n",
    "|**gwOut** | Req. Flag to turn on GWOUT_DOMAIN files. |\n",
    "|**lakeOut** | Req. |Flag to turn on LAKEOUT_DOMAIN files. |\n",
    "|**frxstOut** | Req. |Flag to turn on FRXST output text files. |\n",
    "|**resetHydroAcc** | Req. |Flag to reset accumulation variables in the restart files. |\n",
    "|**streamOrderOut** | Req.| Flag to specify the minimum Strahler order to output. |\n",
    "\n",
    "### hydroPhysics\n",
    "|Argument|Required|Description|\n",
    "|-|-|-|\n",
    "|**dtChSec** | Req.| Channel routing timesetp in seconds. |\n",
    "|**dtTerSec** | Req. |Surface and subsurface routing timestep in seconds. |\n",
    "|**subRouting** | Req.| Flag to turn on/off subsurface routing. |\n",
    "|**ovrRouting** | Req. | Flag to turn on/off overland flow routing. |\n",
    "|**channelRouting** | Req. | Flag to turn on/off channel routing. |\n",
    "|**rtOpt** | Req. | Overland/subsurface routing option. |\n",
    "|**chanRtOpt** | Req. |Channel routing option. |\n",
    "|**udmpOpt** | Req. | User-defined spatial mapping flag to turn on/off. |\n",
    "|**gwBaseSw** | Req. | Groundwater option. |\n",
    "|**gwRestart** | Req. | Flag to use restart states in groundwater scheme. |\n",
    "|**enableCompoundChannel** | Req. | Flag to activate compound channel in the hydro.namelist. 1 - on, 0 - off.|\n",
    "|**compoundChannel** | Req. |Activation flag for compound channel. enableCompoundChannel must be on. |\n",
    "|**enableGwBucketLoss** | Req. |Flag to activate groundwater bucket loss in hydro.namelist. 1 - on, 0 - off. |\n",
    "|**bucket_loss** | Req.| Activation flag for groundwater bucket loss. enableGwBucketLoss must be on. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Calibration Step 2: Configure Calibration Parameter Selection \"calib_parms.tbl\"\n",
    "In addition to the ‘setup.parm’ file, the ‘calib_parms.tbl’ file is needed to direct the workflow to determine which model parameters will be calibrated, along with the range of parameter values. A template table is located under /setup_files/calib_parms.tbl which you can copy and edit for your own calibration workflow experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter,calib_flag,minValue,maxValue,ini\n",
      "bexp,          1,      0.40,      1.90,      1.0\n",
      "smcmax,        1,      0.80,      1.20,      1.0\n",
      "dksat,         1,      0.20,      10.0,      1.0\n",
      "refkdt,        1,      0.10,      4.00,      0.6\n",
      "slope,         1,      0.00,      1.00,      0.1\n",
      "retdeprtfac,   1,      0.10,      10.0,      1.0\n",
      "lksatfac,      1,      10.0,      10000.0,   1000.0\n",
      "zmax,          1,      10.0,      250.0,     25.0\n",
      "expon,         1,      1.00,      8.0,       1.75\n",
      "Coeff,         1,      0.0001,    0.1,       0.001\n",
      "cwpvt,         1,      0.50,      2.0,       1.0\n",
      "vcmx25,        1,      0.60,      1.4,       1.0\n",
      "mp,            1,      0.60,      1.4,       1.0\n",
      "hvt,           1,      0.25,      1.5,       1.0\n",
      "mfsno,         1,      0.50,      2.0,       1.0\n",
      "rsurfexp,      0,      1.0,       6.0,       5.0\n",
      "Bw,            0,      0.1,       10.0,      1.0\n",
      "HLINK,         0,      0.1,       10.0,      1.0\n",
      "ChSSlp,        0,      0.1,       10.0,      1.0\n",
      "MannN,         0,      0.1,       10.0,      1.0\n",
      "Loss,          0,      0.0,       1.0,       0.5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/docker/PyWrfHydroCalib/setup_files\n",
    "cat calib_params.tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*AREZOO*\n",
    "Within this table, you will find:\n",
    "\n",
    "- Parameter -- all the potential parameters to be calibrated\n",
    "- calib_flag -- of 1 or 0. This flag will turn calibration on (1) for that parameter or off (0). \n",
    "- minValues -- The minimum range value for parameter calibration\n",
    "- maxValues -- The maximum range value for parameter calibration\n",
    "- ini -- column specifies the default values to be used for either default un-calibrated values, or the initial values going into the calibration workflow. It is up to you to determine what range is best for your calibration experiment. It is highly encouraged to perform a sensitivity analysis over your region of interest to help determine which parameters have significant impact on hydrologic response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Once the setup.parm file and calibration parameters are set and verified, we can begin the process of initializing databases for calibration. Proceed to *Lesson 2 - Create Database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
